demo()
graphics
demo(graphics)
demo()
a <- 3
a
b <- c(1, 2, 3, 4, 5)
b
c <- c(6:10)
c
a + b
b + c
d <- b + c
plot(cars)
a <- 4
b <- 3
a + b
#Entropy of mushroom data set
#9 edible, 7 inedible
setEntropy <- (-9/16.0 * log2(9/16.0)) - (7/16.0 * log2(7/16.0))
setEntropy
#Gain(S, Size)
#Information gain by splitting on size
sizeSmallEntropy <- (-6/8.0 * log2(6/8.0)) - (2/8.0 * log2(2/8.0))
sizeLargeEntropy <- (-3/8.0 * log2(3/8.0)) - (5/8.0 * log2(5/8.0))
sizeSmallEntropy
sizeLargeEntropy
sizeInfoGain <- setEntropy - (8/16.0 * sizeSmallEntropy) - (8/16.0 * sizeLargeEntropy)
sizeInfoGain
#E(S)
#Entropy of mushroom data set
#9 edible, 7 inedible
setEntropy <- (-9/16.0 * log2(9/16.0)) - (7/16.0 * log2(7/16.0))
sprintf("E(s) = %d", setEntropy)
#E(S)
#Entropy of mushroom data set
#9 edible, 7 inedible
setEntropy <- (-9/16.0 * log2(9/16.0)) - (7/16.0 * log2(7/16.0))
sprintf("E(s) = %f", setEntropy)
#E(S)
#Entropy of mushroom data set
#9 edible, 7 inedible
setEntropy <- (-9/16.0 * log2(9/16.0)) - (7/16.0 * log2(7/16.0))
sprintf(E(s) = %f, setEntropy)
#Gain(S, Size)
#Information gain by splitting on size
sizeSmallEntropy <- (-6/8.0 * log2(6/8.0)) - (2/8.0 * log2(2/8.0))
sizeLargeEntropy <- (-3/8.0 * log2(3/8.0)) - (5/8.0 * log2(5/8.0))
sprintf("E(S_small) = %f", sizeSmallEntropy)
sprintf("E(S_large) = %f", sizeLargeEntropy)
sizeInfoGain <- setEntropy - (8/16.0 * sizeSmallEntropy) - (8/16.0 * sizeLargeEntropy)
sprintf("Gain(S, size) = %f", sizeInfoGain)
#E(S)
#Want to find edible mushrooms
#Entropy of mushroom data set
#9 edible, 7 inedible
setEntropy <- (-9/16.0 * log2(9/16.0)) - (7/16.0 * log2(7/16.0))
sprintf("E(s) = %f", setEntropy)
#Gain(S, Color)
#Information gain by splitting on color
#{Green, Yellow}
colorGreenEntropy <- (-1/3.0 * log2(1/3.0)) - (2/3.0 * log2(2/3.0))
colorYellowEntropy <- (-8/13.0 * log2(8/13.0)) - (5/13.0 * log2(5/13.0))
sprintf("E(S_green) = %f", colorGreenEntropy)
sprintf("E(S_yellow) = %f", colorYellowEntropy)
colorInfoGain <- setEntropy - (3/16.0 * colorGreenEntropy) - (13/16.0 * colorYellowEntropy)
sprintf("Gain(S, color) = %f", colorInfoGain)
#Gain(S, Shape)
#Information gain by splitting on shape
#{Round, Irregular}
shapeRoundEntropy <- (6/12.0 * log2(6/12.0)) - (6/12.0 * log2(6/12.0))
shapeIrregularEntropy <- (3/4.0 * log2(3/4.0)) - (1/4.0 * log2(1/4.0))
sprintf("E(S_round) = %f", shapeRoundEntropy)
sprintf("E(S_irregular) = %f", shapeIrregularEntropy)
shapeInfoGain <- setEntropy - (12/16.0 * shapeRoundEntropy) - (4/16.0 * shapeIrregularEntropy)
sprintf("Gain(S, shape) = %f", shapeInfoGain)
#Gain(S, Shape)
#Information gain by splitting on shape
#{Round, Irregular}
shapeRoundEntropy <- (-6/12.0 * log2(6/12.0)) - (6/12.0 * log2(6/12.0))
shapeIrregularEntropy <- (-3/4.0 * log2(3/4.0)) - (1/4.0 * log2(1/4.0))
sprintf("E(S_round) = %f", shapeRoundEntropy)
sprintf("E(S_irregular) = %f", shapeIrregularEntropy)
shapeInfoGain <- setEntropy - (12/16.0 * shapeRoundEntropy) - (4/16.0 * shapeIrregularEntropy)
sprintf("Gain(S, shape) = %f", shapeInfoGain)
#SUMMARY
sprintf("Gain(S, size) = %f", sizeInfoGain)
sprintf("Gain(S, color) = %f", colorInfoGain)
sprintf("Gain(S, shape) = %f", shapeInfoGain)
#E(S)
#Want to find edible mushrooms
#Entropy of mushroom data set
#9 edible, 7 inedible
setEntropy <- (-9/16.0 * log2(9/16.0)) - (7/16.0 * log2(7/16.0))
sprintf("E(s) = %f", setEntropy)
#Gain(S, Size)
#Information gain by splitting on size
#{Small, Large}
sizeSmallEntropy <- (-6/8.0 * log2(6/8.0)) - (2/8.0 * log2(2/8.0)) #edible - inedible
sizeLargeEntropy <- (-3/8.0 * log2(3/8.0)) - (5/8.0 * log2(5/8.0))
sprintf("E(S_small) = %f", sizeSmallEntropy)
sprintf("E(S_large) = %f", sizeLargeEntropy)
sizeInfoGain <- setEntropy - (8/16.0 * sizeSmallEntropy) - (8/16.0 * sizeLargeEntropy)
sprintf("Gain(S, size) = %f", sizeInfoGain)
#Gain(S, Color)
#Information gain by splitting on color
#{Green, Yellow}
colorGreenEntropy <- (-1/3.0 * log2(1/3.0)) - (2/3.0 * log2(2/3.0))
colorYellowEntropy <- (-8/13.0 * log2(8/13.0)) - (5/13.0 * log2(5/13.0))
sprintf("E(S_green) = %f", colorGreenEntropy)
sprintf("E(S_yellow) = %f", colorYellowEntropy)
colorInfoGain <- setEntropy - (3/16.0 * colorGreenEntropy) - (13/16.0 * colorYellowEntropy)
sprintf("Gain(S, color) = %f", colorInfoGain)
#Gain(S, Shape)
#Information gain by splitting on shape
#{Round, Irregular}
shapeRoundEntropy <- (-6/12.0 * log2(6/12.0)) - (6/12.0 * log2(6/12.0))
shapeIrregularEntropy <- (-3/4.0 * log2(3/4.0)) - (1/4.0 * log2(1/4.0))
sprintf("E(S_round) = %f", shapeRoundEntropy)
sprintf("E(S_irregular) = %f", shapeIrregularEntropy)
shapeInfoGain <- setEntropy - (12/16.0 * shapeRoundEntropy) - (4/16.0 * shapeIrregularEntropy)
sprintf("Gain(S, shape) = %f", shapeInfoGain)
install.packages("tidyverse")
x <- 3
x
x <- 2
y <- 3
x + y
r <- c(2, 3)
a <- c(1, 2, 3, 4)
b <- c(1:4)
b * 5
d <- b * 5
cars
load(cars)
f <- cars
View(f)
library(readr)
training <- read_csv("~/Desktop/ML_CS529/project1/CS529/training.csv")
View(training)
View(training)
View(f)
library(readr)
weatherTraining <- read_csv("~/Desktop/ML_CS529/project1/CS529/weatherTraining.csv")
View(weatherTraining)
View(weatherTraining)
help("colnames")
a <- colnames(weatherTraining)
a
weatherTraining$FakeData
weatherTraining
system("Desktop/ML_CS529/project1/CS529/treeTestLauncher.sh")
View(weatherTraining)
library(tidyverse)
vignette(tibble)
vignette("tibble")
help(clear)
library(haven)
merged <- read_dta("~/Desktop/merged.dta")
View(merged)
View(merged)
test <- merged$female
test
source('~/Desktop/ML_CS529/project1/CS529/treeTest.R', echo=TRUE)
library(readr)
weatherTraining <- read_csv("~/Desktop/ML_CS529/project1/CS529/weatherTraining.csv")
View(weatherTraining)
weatherTraining$last
help("last")
last(weatherTraining)
library(readr)
training <- read_csv("~/Desktop/ML_CS529/project1/CS529/training.csv",
col_names = FALSE)
View(training)
unique(last(training))
training <- read_csv(args[1], col_names = c("index", "string", "classification"))
training <- read_csv("training.csv", col_names = c("index", "string", "classification"))
library(readr)
training <- read_csv("~/Desktop/ML_CS529/project1/CS529/training.csv")
View(training)
unique(last(training))
outcomes <- unique(last(training))
print(outcomes)
outcomes <- unique(last(training))
print(outcomes)
dEnt <- datasetEntropy(last(training), outcomes)
cat("Dataset Entropy = ",dEnt)
source("util.R")
setwd("~/Desktop/ML_CS529/project1/CS529")
source("util.R")
outcomes <- unique(last(training))
print(outcomes)
dEnt <- datasetEntropy(last(training), outcomes)
cat("Dataset Entropy = ",dEnt)
training$index
#Elizabeth E. Esterly
#Last revision 09/21/2017
#treeTest.R
source('~/Desktop/ML_CS529/project1/CS529/treeTest.R', echo=TRUE)
source('~/Desktop/ML_CS529/project1/CS529/treeTest.R', echo=TRUE)
colnames
help(colnames)
colnames(training)
training <- read_csv("training.csv", col_names = FALSE)
View(training)
training$X2[1]
training$X2[2]
str_sub(training$X2[2], 7)
library(stringr)
str_sub(training$X2[2], 7)
str_sub(training$X2[2], 7, 7)
wow <- last(training)
wow[3]
last(training)[3]
